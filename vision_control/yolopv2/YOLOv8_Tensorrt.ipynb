{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gXjoyUkl1Wc"
      },
      "source": [
        "# YOLOv8 Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C4MpBNYlzSa"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_2JhsEJEl90q"
      },
      "outputs": [],
      "source": [
        "# Access Google Drive Folder\n",
        "import os\n",
        "os.chdir(\"gdrive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sHi93xhml_L2"
      },
      "outputs": [],
      "source": [
        "# Create YOLOv8 root folder\n",
        "!mkdir yolov8-tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptFfBeq5mAa8"
      },
      "outputs": [],
      "source": [
        "# Go to YOLOv8 root folder\n",
        "%cd yolov8-tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD26qSXamCfk"
      },
      "outputs": [],
      "source": [
        "# Install YOLOv8\n",
        "%pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJBju7PZmHYc"
      },
      "source": [
        "## Download the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHTp3kVsmKNi"
      },
      "outputs": [],
      "source": [
        "# Download YOLOv8 model\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brSTmpEmLTj"
      },
      "source": [
        "# Tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VUff5dejmNHu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorrt in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (10.2.0.post1)\n",
            "Requirement already satisfied: tensorrt-cu12==10.2.0.post1 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from tensorrt) (10.2.0.post1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e0pZtlcCmQkE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorrt_lean\n",
            "  Downloading tensorrt_lean-10.7.0.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorrt_lean_cu12==10.7.0 (from tensorrt_lean)\n",
            "  Downloading tensorrt_lean_cu12-10.7.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt_lean, tensorrt_lean_cu12\n",
            "  Building wheel for tensorrt_lean (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_lean: filename=tensorrt_lean-10.7.0-py2.py3-none-any.whl size=16410 sha256=0f9d9aa80a23baa96068912773956371317a13a17169d60f33697bca040ba35c\n",
            "  Stored in directory: /home/irman/.cache/pip/wheels/1f/a8/a8/9c9b2103a10b8c613f7cffa979cc1cbe05e9ed1e03363cbb97\n",
            "  Building wheel for tensorrt_lean_cu12 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_lean_cu12: filename=tensorrt_lean_cu12-10.7.0-py2.py3-none-any.whl size=17632 sha256=772dcfb243e1accdb2fb0d53f3c451d0b880dd850a77c3d5db1ad71b20a9a674\n",
            "  Stored in directory: /home/irman/.cache/pip/wheels/bb/12/eb/b2d5473675c7a2e2912e011667c8a0c738f7676207023b731e\n",
            "Successfully built tensorrt_lean tensorrt_lean_cu12\n",
            "Installing collected packages: tensorrt_lean_cu12, tensorrt_lean\n",
            "Successfully installed tensorrt_lean-10.7.0 tensorrt_lean_cu12-10.7.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt_lean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fAhaRj11mS1m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorrt_dispatch\n",
            "  Downloading tensorrt_dispatch-10.7.0.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorrt_dispatch_cu12==10.7.0 (from tensorrt_dispatch)\n",
            "  Downloading tensorrt_dispatch_cu12-10.7.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt_dispatch, tensorrt_dispatch_cu12\n",
            "  Building wheel for tensorrt_dispatch (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_dispatch: filename=tensorrt_dispatch-10.7.0-py2.py3-none-any.whl size=16465 sha256=bf30453f0783c6e8b8e37ca8b1e62c50c2d975f7075455bba8909eb8fc80f792\n",
            "  Stored in directory: /home/irman/.cache/pip/wheels/ec/25/80/0118a4bcfeefe42e477d604df48c0f6f96ab202933e5c111c6\n",
            "  Building wheel for tensorrt_dispatch_cu12 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_dispatch_cu12: filename=tensorrt_dispatch_cu12-10.7.0-py2.py3-none-any.whl size=17700 sha256=40931e57a6d9b842776fcc2ca806944f0e0113444da5fae525b4b655299873a0\n",
            "  Stored in directory: /home/irman/.cache/pip/wheels/44/65/d6/c489263d810ed7cd2abaf83063f96f4360a8eb8b3a14bca51a\n",
            "Successfully built tensorrt_dispatch tensorrt_dispatch_cu12\n",
            "Installing collected packages: tensorrt_dispatch_cu12, tensorrt_dispatch\n",
            "Successfully installed tensorrt_dispatch-10.7.0 tensorrt_dispatch_cu12-10.7.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorrt_dispatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3zR8n35m5Kp6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (1.16.1)\n",
            "Requirement already satisfied: onnxsim in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (0.4.36)\n",
            "Requirement already satisfied: onnxruntime-gpu in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (1.18.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnx) (1.24.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnx) (5.27.2)\n",
            "Requirement already satisfied: rich in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: coloredlogs in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnxruntime-gpu) (24.3.25)\n",
            "Requirement already satisfied: packaging in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnxruntime-gpu) (24.1)\n",
            "Requirement already satisfied: sympy in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from onnxruntime-gpu) (1.12.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from rich->onnxsim) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from rich->onnxsim) (4.12.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/irman/anaconda3/envs/zed_sdk/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx onnxsim onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2UxZjv9JmUaY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.2.0.post1\n"
          ]
        }
      ],
      "source": [
        "import tensorrt\n",
        "print(tensorrt.__version__)\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V62zTVoImXKU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.105 üöÄ Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7933MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.8s, saved as yolov8n.onnx (6.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.2.0.post1...\n",
            "[12/21/2024-19:48:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 863, GPU 1669 (MiB)\n",
            "[12/21/2024-19:48:05] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2170, GPU +414, now: CPU 3186, GPU 2070 (MiB)\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure ‚ùå 4.1s: 'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'\n"
          ]
        }
      ],
      "source": [
        "# Export YOLOv8 Model to Tensorrt\n",
        "!yolo export model=yolov8n.pt format=engine half=True device=0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.105 üöÄ Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7933MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.9s, saved as yolov8n.onnx (6.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.2.0.post1...\n",
            "[12/21/2024-19:46:16] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 863, GPU 1681 (MiB)\n",
            "[12/21/2024-19:46:20] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2170, GPU +401, now: CPU 3186, GPU 2082 (MiB)\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure ‚ùå 4.3s: 'tensorrt_bindings.tensorrt.IBuilderConfig' object has no attribute 'max_workspace_size'\n"
          ]
        }
      ],
      "source": [
        "!yolo export model=yolov8n.pt format=engine device=0 half=True workspace=12000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ZYA3k2mgz8"
      },
      "source": [
        "## Inference on Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DhS9BTRml_z"
      },
      "outputs": [],
      "source": [
        "# Inference Using YOLOv8 Model\n",
        "!yolo detect predict model=yolov8x.pt source=\"https://ultralytics.com/images/bus.jpg\" device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QIl5j75mvyB"
      },
      "outputs": [],
      "source": [
        "# Inference Using YOLOv8 Tensorrt\n",
        "!yolo detect predict model=yolov8x.engine source=\"https://ultralytics.com/images/bus.jpg\" device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHSN2qk_ivN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Load the images\n",
        "image1 = Image.open(\"runs/detect/predict/bus.jpg\")\n",
        "image2 = Image.open(\"runs/detect/predict2/bus.jpg\")\n",
        "\n",
        "w, h = image1.size\n",
        "new_width = int(w/2)\n",
        "new_height = int(h/2)\n",
        "\n",
        "# Resize the images\n",
        "image1 = image1.resize((new_width, new_height))\n",
        "image2 = image2.resize((new_width, new_height))\n",
        "\n",
        "# Display the images side by side\n",
        "display(image1, image2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23v8tX4m3Bi"
      },
      "source": [
        "## mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_VvMCQSm4Zy"
      },
      "outputs": [],
      "source": [
        "# mAP Calculation YOLOv8 Model\n",
        "!yolo detect val model=yolov8x.pt data=coco128.yaml iou=0.5 imgsz=640 name=yolov8x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0LDOtg8nGE2"
      },
      "outputs": [],
      "source": [
        "# mAP Calculation YOLOv8 Tensorrt\n",
        "!yolo detect val model=yolov8x.engine data=coco128.yaml iou=0.5 imgsz=640 name=yolov8x-tensorrt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7GeHBg_m4km"
      },
      "source": [
        "## Inference on Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1PyUqCanKJW"
      },
      "outputs": [],
      "source": [
        "# Download modules\n",
        "!gdown https://drive.google.com/uc?id=1RskX1wXVF0xSMAPgpkU-EsaUv8tD7lvS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khIoR0ccnKWK"
      },
      "outputs": [],
      "source": [
        "# Unzip the modules\n",
        "!unzip modules.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ywuQHtHukaAj"
      },
      "outputs": [],
      "source": [
        "# Create inference folder\n",
        "!mkdir inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zANblaROkbTH"
      },
      "outputs": [],
      "source": [
        "# Download the video\n",
        "!gdown https://drive.google.com/uc?id=11Z0BMXcKNdQmJNyBejWqU9V6z7gEloMZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "N9KXMeCKke7L"
      },
      "outputs": [],
      "source": [
        "# Move the video to inference folder\n",
        "!mv road.mp4 inference/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L3HtPyVwkleD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import pathlib\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import modules.utils as utils\n",
        "\n",
        "def get_detection_result(model, frame):\n",
        "    # Update object localizer\n",
        "    results = model.predict(frame, imgsz=640, conf=0.5, verbose=False)\n",
        "    result = results[0].cpu()\n",
        "\n",
        "    # Get information from result\n",
        "    box = result.boxes.xyxy.numpy()\n",
        "    conf = result.boxes.conf.numpy()\n",
        "    cls = result.boxes.cls.numpy().astype(int)\n",
        "\n",
        "    return cls, conf, box\n",
        "\n",
        "def detection(model_path, source, name):\n",
        "    # Check File Extension\n",
        "    file_extension = pathlib.Path(model_path).suffix\n",
        "\n",
        "    # Load the Model\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Class Name and Colors\n",
        "    label_map = model.names\n",
        "    COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
        "\n",
        "    # FPS Detection\n",
        "    frame_count = 0\n",
        "    total_fps = 0\n",
        "    avg_fps = 0\n",
        "\n",
        "    # FPS Video\n",
        "    video_cap = cv2.VideoCapture(source)\n",
        "    total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = int(video_cap.get(3))\n",
        "    frame_height = int(video_cap.get(4))\n",
        "\n",
        "    video_frames = []\n",
        "\n",
        "    while video_cap.isOpened():\n",
        "        ret, frame = video_cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # # Start Time\n",
        "        start = time.time()        \n",
        "        # Detection\n",
        "        cls, conf, box = get_detection_result(model, frame)\n",
        "\n",
        "        # Pack together for easy use\n",
        "        detection_output = list(zip(cls, conf, box))\n",
        "        image_output = utils.draw_box(frame, detection_output, label_map, COLORS)\n",
        "\n",
        "        end = time.time()\n",
        "        # # End Time\n",
        "\n",
        "        # Draw FPS\n",
        "        frame_count += 1\n",
        "        fps = 1 / (end - start)\n",
        "        total_fps = total_fps + fps\n",
        "        avg_fps = total_fps / frame_count\n",
        "\n",
        "        image_output = utils.draw_fps(avg_fps, image_output)\n",
        "\n",
        "        # Append frame to array\n",
        "        video_frames.append(image_output)\n",
        "\n",
        "        #\n",
        "        print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
        "\n",
        "    # Get a file name\n",
        "    file_name = utils.get_name(source)\n",
        "    # Get Save Path\n",
        "    folder_name = name\n",
        "    save_path = utils.get_save_path(file_name, folder_name)\n",
        "    # Create VideoWriter object.\n",
        "    out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
        "\n",
        "    for frame in video_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    print(\"Video is saved in: \"+save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcl651SGko9V"
      },
      "outputs": [],
      "source": [
        "detection(\"yolov8x.pt\", \"inference/road.mp4\", \"detection-yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTZH7sCHkpfr"
      },
      "outputs": [],
      "source": [
        "# Download the result\n",
        "from google.colab import files\n",
        "\n",
        "files.download('result/detection-yolov8/road.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9UVb02-nKaw"
      },
      "outputs": [],
      "source": [
        "detection(\"yolov8x.engine\", \"inference/road.mp4\", \"detection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjv-OcATnKdD"
      },
      "outputs": [],
      "source": [
        "# Download the result\n",
        "from google.colab import files\n",
        "\n",
        "files.download('result/detection/road.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
